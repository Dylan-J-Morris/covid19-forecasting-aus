{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-poster')\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "import glob\n",
    "    \n",
    "from Reff_functions import *\n",
    "from Reff_constants import *\n",
    "from scipy.stats import gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code taken from read_in_cases from Reff_functions. Preprocessing was not helpful for this situation.\n",
    "def read_cases_lambda(case_file_date):\n",
    "    path = \"../data/COVID-19 UoM \"+case_file_date+\"*.xlsx\"\n",
    "\n",
    "    for file in glob.glob(path):\n",
    "        df_NNDSS = pd.read_excel(file,\n",
    "                           parse_dates=['SPECIMEN_DATE','NOTIFICATION_DATE','NOTIFICATION_RECEIVE_DATE','TRUE_ONSET_DATE'],\n",
    "                           dtype= {'PLACE_OF_ACQUISITION':str})\n",
    "        df_NNDSS.PLACE_OF_ACQUISITION.fillna('00038888',inplace=True) #Fill blanks with simply unknown\n",
    "\n",
    "       # df_NNDSS['date_inferred'] = df_NNDSS.TRUE_ONSET_DATE\n",
    "      #  df_NNDSS.loc[df_NNDSS.TRUE_ONSET_DATE.isna(),'date_inferred'] = df_NNDSS.loc[df_NNDSS.TRUE_ONSET_DATE.isna()].NOTIFICATION_DATE - timedelta(days=5)\n",
    "      #  df_NNDSS.loc[df_NNDSS.date_inferred.isna(),'date_inferred'] = df_NNDSS.loc[df_NNDSS.date_inferred.isna()].NOTIFICATION_RECEIVE_DATE - timedelta(days=6)    \n",
    "    df_NNDSS['imported'] = df_NNDSS.PLACE_OF_ACQUISITION.apply(lambda x: 1 if x[-4:]=='8888' and x != '00038888' else 0)\n",
    "    df_NNDSS['local'] = 1 - df_NNDSS.imported\n",
    "\n",
    "    df_interim = df_NNDSS[['NOTIFICATION_DATE','STATE','imported','local']] \n",
    "    #df_interim = df_interim[~np.isnat(df_interim.NOTIFICATION_DATE)] #Get rid of non-existent dates.\n",
    "    # Importantly, imported and local are indicator variables in df_interim.\n",
    "\n",
    "    #df_state = df_NNDSS[['NOTIFICATION_DATE','STATE','imported','local']].groupby(['STATE','NOTIFICATION_DATE']).sum()\n",
    "    return(df_interim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interim = read_cases_lambda('29Jun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_cases_lambda(interim_data, remove_territories=True):\n",
    "    #Remove non-existent notification dates\n",
    "    interim_data = interim_data[~np.isnat(interim_data.NOTIFICATION_DATE)]\n",
    "    \n",
    "    #Filter out territories\n",
    "    if(remove_territories):\n",
    "        df_linel = interim_data[(interim_data['STATE']!='NT') & (interim_data['STATE']!='ACT')]\n",
    "\n",
    "    #Melt down so that imported and local are no longer columns. Allows multiple draws for infection date.\n",
    "    #i.e. create linelist data\n",
    "    df_linel = df_linel.melt(id_vars = ['NOTIFICATION_DATE','STATE'], var_name = 'SOURCE',value_name='n_cases')\n",
    "\n",
    "    #Reset index or the joining doesn't work\n",
    "    df_linel = df_linel[df_linel.n_cases!=0]\n",
    "    df_linel = df_linel.reset_index(drop=True)\n",
    "    return(df_linel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linel = tidy_cases_lambda(df_interim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Inferring infection dates\n",
    "$\\Lambda$ depends on the infection date (ID), while the data contains the notification date (ND). We obtain ID through the following relationship:\n",
    "$$\n",
    "ID = ND - reporting\\_delay - incubation\\_period.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gamma distribution was fitted to case data using the MLE algorithm to produce distributions for reporting delay and incubation period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##uncomment for debugging\n",
    "# notification_dates = df_linel['NOTIFICATION_DATE']\n",
    "# mean_rd = 5.47\n",
    "# sd_rd = 4.04\n",
    "# mean_inc = 2.0\n",
    "# sd_inc = 1.41\n",
    "# nreplicates = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##gamma draws take arguments (shape, scale)\n",
    "def draw_inf_dates(df_linelist, mean_rd=5.47, sd_rd=4.04,\n",
    "                    mean_inc=2.0, sd_inc=1.41, nreplicates=1):\n",
    "\n",
    "    notification_dates = df_linelist['NOTIFICATION_DATE']\n",
    "    nsamples = notification_dates.shape[0]\n",
    "\n",
    "    #    DEFINE DELAY DISTRIBUTION\n",
    "    #     mean_rd = 5.47\n",
    "    #     sd_rd = 4.04\n",
    "    scale_rd = mean_rd/(sd_rd)**2\n",
    "    shape_rd = mean_rd/scale_rd\n",
    "\n",
    "    # DEFINE INCUBATION PERIOD DISTRIBUTION\n",
    "    #     mean_inc = 2.0\n",
    "    #     sd_inc = 1.41\n",
    "    scale_inc = mean_inc/(sd_inc)**2\n",
    "    shape_inc = mean_inc/scale_inc\n",
    "\n",
    "    #Draw from distributions - these are long vectors\n",
    "    inc_period = np.random.gamma(shape_inc, scale_inc, size = (nsamples*nreplicates))\n",
    "    rep_delay = np.random.gamma(shape_rd, scale_rd, size = (nsamples*nreplicates))\n",
    "\n",
    "    #infection date is id_nd_diff days before notification date. This is also a long vector.\n",
    "    id_nd_diff = inc_period + rep_delay\n",
    "\n",
    "    #Minutes aren't included in df. Take the ceiling because the day runs from 0000 to 2359. This can still be a long vector.\n",
    "    whole_day_diff = np.ceil(id_nd_diff) \n",
    "    time_day_diffmat = whole_day_diff.astype('timedelta64[D]').reshape((nsamples, nreplicates))\n",
    "\n",
    "    #Vector must be coerced into a nsamples by nreplicates array. Then each column must be subtracted from notification_dates. \n",
    "    #Subtract days off of notification dates.\n",
    "\n",
    "    notification_mat = np.tile(notification_dates, (nreplicates,1)).T #notification_dates is repeated as a column nreplicates times.\n",
    "\n",
    "    infection_dates = notification_mat - time_day_diffmat\n",
    "\n",
    "    #Make infection dates into a dataframe\n",
    "    datecolnames = [*map(str,range(nreplicates))]\n",
    "    infdates_df = pd.DataFrame(infection_dates,columns = datecolnames)\n",
    "    \n",
    "    #Uncomment this if theres errors\n",
    "    #print([df_linelist.shape, infdates_df.shape])\n",
    "    \n",
    "    \n",
    "    #Combine infection dates and original dataframe\n",
    "    df_inf = pd.concat([df_linelist, infdates_df], axis=1, verify_integrity=True)\n",
    "\n",
    "    return(df_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inf = draw_inf_dates(df_linel, nreplicates=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_by_infection_date(infections_wide):\n",
    "    datecolnames = [*infections_wide.columns[4:]]\n",
    "    df_combined = infections_wide[['STATE','SOURCE',datecolnames[0],'n_cases']].groupby(['STATE', datecolnames[0],'SOURCE']).sum()\n",
    "\n",
    "    #For each column (cn=column number): concatenate each sample as a column.\n",
    "    for cn in range(1,len(datecolnames)):\n",
    "        df_addin = infections_wide[['STATE','SOURCE',datecolnames[cn],'n_cases']].groupby(['STATE', datecolnames[cn],'SOURCE']).sum()\n",
    "        df_combined = pd.concat([df_combined,df_addin], axis=1, ignore_index = True)\n",
    "\n",
    "    #NaNs are inserted for missing values when concatenating. If it's missing, there were zero infections\n",
    "    df_combined[np.isnan(df_combined)]=0\n",
    "    #Rename the index.\n",
    "    df_combined.index.set_names([\"STATE\",\"INFECTION_DATE\",\"SOURCE\"], inplace=True)\n",
    "\n",
    "    #return(df_combined)\n",
    "\n",
    "    ##INCLUDE ALL DAYS WITH ZERO INFECTIONS IN THE INDEX AS WELL.\n",
    "\n",
    "    # Reindex to include days with zero total infections.\n",
    "    local_infs = df_combined.xs('local',level='SOURCE')\n",
    "    imported_infs = df_combined.xs('imported',level='SOURCE')\n",
    "    statelist = [*df_combined.index.get_level_values('STATE').unique()]\n",
    "\n",
    "    #Should all states have the same start date? Current code starts from the first case in each state.\n",
    "    #For the same start date:\n",
    "    local_statedict = dict(zip(statelist, np.repeat(None, len(statelist))))\n",
    "    imported_statedict = dict(zip(statelist, np.repeat(None, len(statelist))))\n",
    "\n",
    "    #Determine start date as the first infection date for all. \n",
    "    #start_date = np.datetime64(\"2020-02-01\")\n",
    "    start_date = df_combined.index.get_level_values('INFECTION_DATE').min()\n",
    "\n",
    "    #Determine end dates as the last infected date by state.\n",
    "    index_only = df_combined.index.to_frame()\n",
    "    index_only = index_only.reset_index(drop=True)\n",
    "    maxdates = index_only.groupby(['STATE'])['INFECTION_DATE'].max()\n",
    "\n",
    "    for aus_state in statelist:\n",
    "        state_data = local_infs.xs(aus_state, level='STATE')\n",
    "        #start_date = state_data.index.min()\n",
    "\n",
    "        #dftest.index=dftest.reindex(alldates, fill_value=0)\n",
    "\n",
    "        alldates = pd.date_range(start_date, maxdates[aus_state]) #All days from start_date to the last infection day.\n",
    "        local_statedict[aus_state] = state_data.reindex(alldates, fill_value=0)\n",
    "\n",
    "    for aus_state in statelist:\n",
    "        state_data = imported_infs.xs(aus_state, level='STATE')\n",
    "        alldates = pd.date_range(start_date, maxdates[aus_state])\n",
    "        imported_statedict[aus_state] = state_data.reindex(alldates, fill_value=0)\n",
    "\n",
    "    #Convert dictionaries to data frames\n",
    "    df_local_inc_zeros = pd.concat(local_statedict)\n",
    "    df_local_inc_zeros['SOURCE']='local'\n",
    "    df_imp_inc_zeros = pd.concat(imported_statedict)\n",
    "    df_imp_inc_zeros['SOURCE']='imported'\n",
    "\n",
    "    #Merge dataframes and reindex. \n",
    "    df_inc_zeros = pd.concat([df_local_inc_zeros, df_imp_inc_zeros])\n",
    "\n",
    "    df_inc_zeros = df_inc_zeros.reset_index()\n",
    "    df_inc_zeros= df_inc_zeros.groupby(['level_0',\"level_1\",\"SOURCE\"]).sum()\n",
    "    df_inc_zeros.index = df_inc_zeros.index.rename(['STATE','INFECTION_DATE',\"SOURCE\"])\n",
    "\n",
    "    return(df_inc_zeros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inc_zeros = index_by_infection_date(df_inf)\n",
    "df_inc_zeros.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(df_inc_zeros, axis=0) #Approximately the length of initial notification dates. Differences in numbers: start date?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Calculating Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Lambda_t(w_s) = \\sum_{s=1}^t (I_{t-s}^{local} + I_{t-s}^{imported})w_s = \\sum_{s=1}^t I_{t-s}w_s,\n",
    "$$\n",
    "where $w_s$ is the probability that the generation interval is $s$ and $I_t$ is the number of infected individuals at time $t$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2a: Discretizing the gamma generation interval distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the formula for $\\Lambda_t$, we sum over $w$. We should therefore consider generation interval as a discrete random variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define gamma distribution for generation interval\n",
    "mean_gen = 2.5\n",
    "sd_gen = 1.75\n",
    "scale_gen = mean_gen/(sd_gen)**2\n",
    "shape_gen = mean_gen/scale_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTRUCT DISCRETE DISTRIBUTION\n",
    "\n",
    "trunc_days = 21\n",
    "shift=0\n",
    "xmids = [x+shift for x in range(trunc_days+1)] #Set shift = 0.5 if midpoints are used. \n",
    "\n",
    "#Find f(x) for x in xmids where f is gamma pdf. \n",
    "gamma_vals = gamma.pdf(xmids, a=shape_gen, scale=scale_gen)\n",
    "\n",
    "#Normalize by the sum of discrete values.\n",
    "disc_gamma = gamma_vals/sum(gamma_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check\n",
    "print(\"Sum of gamma values is \" + str(sum(gamma_vals))+\"; \\n Sum of normalised gamma values is \" + str(sum(disc_gamma)))\n",
    "#Everything worked as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare continuous and discrete distributions\n",
    "xrange = np.linspace(0,trunc_days,150)\n",
    "fig,ax = plt.subplots(figsize=(12,9))\n",
    "w = ax.bar(xmids,height=disc_gamma, width=1,label = \"discrete\")\n",
    "ax.set_title(\"Generation time distribution\")\n",
    "ax.plot(xrange, gamma.pdf(xrange, a=shape_gen, scale=scale_gen), linewidth=4,alpha=0.8, color=\"orange\", label = 'continuous')\n",
    "ax.set_xlabel('Days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2b: Actually calculating $\\Lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ws is the discretised gamma distribution; reversed due to the formula for lambda t.\n",
    "ws = [*reversed(disc_gamma[1:(trunc_days+1)])]\n",
    "\n",
    "\n",
    "#Calculate lambda t for a given t in one state. \n",
    "def calculate_lambda_t(state_df, t, trunc_days = 21, ws=ws):\n",
    "    #t = predict_date_range[30]\n",
    "    #state_df = input_state\n",
    "\n",
    "    tstart= t-np.timedelta64(trunc_days,'D')\n",
    "    relevant_dates = pd.date_range(tstart, t-np.timedelta64(1,'D'))\n",
    "    reldates_df = state_df.loc[relevant_dates]\n",
    "\n",
    "    #Dates don't matter, since we're calculating lambda t for t = t.\n",
    "    reldates_df = reldates_df.reset_index(drop=True)\n",
    "    ws_mat = pd.DataFrame(np.tile(ws, (reldates_df.shape[1],1)).T)\n",
    "\n",
    "    #lambda_t=sum(reldates*ws)\n",
    "    lambda_t = np.sum(reldates_df.mul(ws_mat), axis=0)\n",
    "    return(lambda_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop over states and times to calculate all lambda t's\n",
    "#Input: imported/local counts of infections by date and state. Each column should be a different sample.\n",
    "#Output: Lambda t by date and state. Each column corresponds to a different original sample. \n",
    "def calculate_all_lambdas(infection_df):\n",
    "\n",
    "    #Depending on data format, flatten if necessary\n",
    "    if type(infection_df.index)!=pd.RangeIndex:\n",
    "        infection_df = infection_df.reset_index()\n",
    "    \n",
    "    #Create data frame with the total number of infections.\n",
    "    I_total = infection_df.groupby(['STATE',\"INFECTION_DATE\"]).sum()\n",
    "    \n",
    "    #Find states and preallocate to dict\n",
    "    statelist = [*I_total.index.get_level_values('STATE').unique()]\n",
    "    state_dict = dict(zip(statelist, np.repeat(None, len(statelist))))\n",
    "    \n",
    "    predict_reff_from = np.datetime64('2020-02-01')\n",
    "\n",
    "    #Calculate Reff for each state.\n",
    "    for state in statelist: \n",
    "        #print(state)\n",
    "        input_state_df = I_total.xs(state, level='STATE')\n",
    "        tmax = input_state_df.index.get_level_values('INFECTION_DATE').max()\n",
    "        predict_date_range = pd.date_range(predict_reff_from, tmax)\n",
    "\n",
    "        date_dict = dict(zip(predict_date_range, np.repeat(None, len(predict_date_range))))\n",
    "\n",
    "        #Find lambda t for every day.\n",
    "        for t in predict_date_range:\n",
    "            #print(t)\n",
    "            date_dict[t] = calculate_lambda_t(input_state_df, t).to_numpy()\n",
    "\n",
    "\n",
    "        state_dict[state]=date_dict\n",
    "\n",
    "    #Convert dict to a dataframe \n",
    "    lambda_df = pd.DataFrame.from_dict({(i,j): state_dict[i][j] \n",
    "                                for i in state_dict.keys() \n",
    "                                for j in state_dict[i].keys()},\n",
    "                                orient='index')\n",
    "    lambda_df.index = pd.MultiIndex.from_tuples(lambda_df.index,names = ['STATE','INFECTION_DATE'])\n",
    "    \n",
    "    return(lambda_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = calculate_all_lambdas(df_inc_zeros)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
